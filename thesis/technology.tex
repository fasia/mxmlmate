%### 
\subsection{Technology Stack}
%### 
\label{sec:tech}
Over the time of its development \xmlmate has amassed quite a technology stack, 
which has grown to include not only a number of \xml processing libraries, but also communication, instrumentation, and serialization frameworks. 
In the following sections I would like to give a brief overview of the technologies used.
%###  
\subsubsection{Xom}
%### 
\xom\cite{xom} is a \java library for handling \xml documents at the core of \xmlmate. 
It offers in-memory representation of \xml tree structures as well as support for Namespaces in \xml, {\small XPath 1.0}, {\small XSLT 1.0}, 
{\small XInclude}, {\small xml:id}, {\small xml:base}, Canonical \xml, and Exclusive Canonical \xml.
I decided for it in favor of {\small SAX}, {\small StAX}, {\small DOM4j} and {\small jDOM} because of its simplicity and efficiency.
It is also the only \xml API that ensures correctness very strictly - \xom only allows to create namespace well-formed XML documents, 
which coincides with one of the underlying principles of \xmlmate{} - generating valid and well-formed data.
Furthermore, \xom is open to extension, which allows for easy enhancements and adaptations to make it suitable 
for building the basis of genetic representations of \xml trees (further described in \cref{sec:repr}).
\improvement[inline]{Add some xml specification and example}
%### 
\subsubsection{Xerces2}
%### 
\xerces\cite{xerces} is a \java library for parsing, validating and manipulating XML documents, which most importantly to \xmlmate, has support for W3C XML Schema 1.1 (Working Drafts, December 2009). 
At the heart of \xmlmate lies a representation of an \xsd, which is used as a blueprint for generating new \xml instances and modifying existing ones. 
This representation is implemented with \xerces, as at the time of conception it was really the only available \xsd implementation for \java. 
\xerces mainly provides access to the definitions of a schema as well as a mechanism for validating \xml instances.
Unfortunately, it only exposes its functionality via \java interfaces, which makes enhancements and adaptations rather hard, but not impossible, as you will see in \cref{sec:repr}.
\improvement[inline]{Add some xsd specs and example}
%### 
\subsubsection{PIN}
%### 
{\small Intel} \pin\cite{pin} is a dynamic binary instrumentation framework for the IA-32 and x86-64 instruction-set architectures 
that enables the creation of program analysis tools, which perform the instrumentation at run time on  
compiled binary files. Thus, it requires no recompiling of source code and can support instrumenting programs that dynamically generate code.
\pin allows a tool to insert arbitrary code (written in {\small C} or \cpp) in arbitrary places in the executable, for which it 
provides an API that abstracts away the underlying instruction-set idiosyncrasies and allows context information 
such as register contents to be passed to the injected code as parameters. It also automatically saves and restores 
the registers that are overwritten by the injected code so the application continues to work.

Generally, the instrumentation with \pin consists of two components: a mechanism that decides where and what code to insert, 
and the code to be executed at insertion points. These two components, called \emph{instrumentation} and \emph{analysis} 
code are hosted in a single executable called a \emph{pintool}, which functions like a plugin to the \pin framework.
A pintool can register callbacks on different levels of granularity, varying from single instructions over procedures
to entire binary images, in order to receive context-dependent information and access to values of particular interest.

\pin provides two modes of execution: just-in-time (jit) and probe. The latter is designed for replacing
entire individual routines and offers a very small API, but relatively good performance. The former provides
a rich API and access to granularity levels much more precise than routine level, but the instrumented process
suffers a significant performance penalty. For the purpose of using \pin as part of specific fitness functions
a high level of detail is necessary, which is why jit mode is used. To somewhat compensate for the performance
loss, a system has been put in place, which allows to parallelize the execution of processes instrumented with
\pin. \Cref{sec:par} gives more details about these parallelization efforts.

\improvement[inline]{Mention gcov}
\unsure[inline]{Mention valgrind}
%### 
\subsubsection{ZeroMQ}
%###
\label{sec:zmq}
{\small ZeroMQ}\cite{zmq} (or \zmq as it as actually called) is an extremely efficient messaging library, 
which is very well suited for use in concurrent or distributed applications. \zmq regards messages as 
completely transparent blobs of data which are to be transported across predefined communication channels 
between sockets. Rather than unnecessarily defining its own transfer protocol, \zmq works on top of already exiting 
ones like \texttt{inproc}, \texttt{IPC}, \texttt{TCP}, \texttt{TIPC} and multicast such as \texttt{pgm} or \texttt{epgm}.
Out of the box \zmq provides its users with several communication patterns that can be either used directly or combined 
into more complex patterns, which remain easy to manage and use. Some basic patterns are \texttt{Request/Response}, 
\texttt{Publish/Subscribe}, or \texttt{Push/Pull} among others.
There are implementations of \zmq in many programming languages, of which the ones for \java, \python, {\small C}, 
and \cpp are actually used in \xmlmate. 

It is very easy to get started with \zmq in all programming languages - the basic concept is the
same everywhere: the program that uses \zmq must first set up a so called \emph{context}, which then becomes
host to \emph{sockets}, which, in turn, are either bound or connected to \emph{endpoints} of some transport
channel. A socket can have arbitrarily many ingoing and outgoing connections and \zmq automatically reconnects
it to any peers in case the underlying connection gets interrupted. Furthermore, a socket can be either bound
or connected to its endpoint with \emph{binding} being preferred when the component behind the socket is a
static component of the overall system; only one socket can be bound per endpoint. Conversely, a socket is
\emph{connected} when the component behind it is more dynamic in nature and may leave and rejoin the system
arbitrarily, or when the number of instances of this component is not known a priori. Sockets joined at
different ends of a connection must use different methods, in practice, this means that on one end of the line
there is a single bound socket, and on the other there is a variable number of connected sockets, which may
come and go during runtime.

There are different types of sockets: \texttt{PUB}, \texttt{SUB}, \texttt{REQ}, \texttt{REP}, \texttt{PUSH}, 
\texttt{PULL}, as well as some other, more exotic types. The different types of sockets can be plugged together
like their names suggest, for example \xmlmate combines a multitude of \texttt{PUSH} and \texttt{PULL} sockets
to create a processing pipeline for its \xml files and their fitness scores.

Beside \zmq there are other messaging solutions, some of which were considered for use in \xmlmate. One such
library is {\small RabbitMQ}\cite{rabbitmq} - it implements the AMQP protocol and as such requires a central
message broker. This means an additional process in need of customization and deployment would be needed, and
writing client side code is also somewhat more difficult; this is why {\small RabbitMQ} was decided against.

Then there is {\small nanomsg}\cite{nanomsg}, which was written by one of the authors of \zmq. 
It is similarly brokerless, more lightweight and efficient than \zmq, and has an even easier to use API, which
for example does not burden its users with the concept of a context; however, it is still in beta and lacks
the gigantic community support like that of \zmq, which ultimately lead me to not choosing it either.
%### 
\subsubsection{MessagePack}
%### 
Because a messaging library only solves the problem of getting \emph{arbitrary data} between peers, it 
alone does not suffice for creating a fully fledged communication protocol - this is where serialization/deserialization libraries 
usually come in. \msgpack\cite{msgpack} is one such serialization format that is highly efficient as it based on 
binary representation of data. It is implemented as a library in at least 20 programming languages. 
Once again, \xmlmate uses the ones for \java, \python, {\small C}, and \cpp.
While \msgpack is very efficient in what it does, it has some disadvantages such as 
\begin{itemize}
  \item Integer values are limited to be in $[-2^{63}, 2^{64}-1]$.
  \item The maximum length of an array or string is limited to $2^{32}-1$.
  \item It is the user's responsibility to ensure correct endianness across all endpoints.
\end{itemize}

There is another relatively young binary serialization format \emph{CBOR}\footnote{\url{http://tools.ietf.org/html/rfc7049}} 
that does not have many of {\small MessagePack's} disadvantages, while being comparatively as efficient.
There are implementations in {\small C}, \python and \java; however, at the time of {\small XMLMate's}
conception I did not know of their existence. This might be a subject of some future enhancement.
\info{Mention in Future Work}
% C (https://github.com/upwhere/ccbor), 
% Python (https://code.google.com/p/cbor/) 
% and Java (https://github.com/c-rack/cbor-java)
\unsure{Mention Protobuf, Cap'n Proto, SBE, and FlatBuffers}
%### 
\subsubsection{GNU Trove}
%### 
\label{sec:trove}
The GNU Trove \java library provides performant and memory efficient alternative implementations of the
standard \java collections API, and, in addition, offers collections supporting primitive types. 

A disadvantage of \java's standard collections, which can often quickly become a performance bottleneck in
applications that handle lots of primitive values, is their lack of direct support for those. In
order to store primitive values in the standard collections, it is necessary to envelop each and every single
value in its own wrapper object - a process known as \emph{boxing}, which incurs costs both in memory use and
computing time. This practice is so common that since version $1.5$ \java offers autoboxing functionality,
whereby programmers can put primitive values where their wrapper counterparts are expected and vice versa, and
the \java compiler would perform the necessary boxing and unboxing automatically, thus hiding the additional
cost from inexperienced programmers. In most cases, these additional costs can be calmly neglected, but
sometimes they cannot. In order to exclude the possibility of this becoming a problem and suddenly sneaking
up, the decision was made to go with Trove collections from the beginning. These collections have since found
their special use with the many details of the various evaluation result types, e.g. storing big amounts of
memory addresses.