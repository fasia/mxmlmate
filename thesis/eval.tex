\section{Evaluation}
\label{sec:evaluation}
The previous sections discussed the main ideas and some technical details behind
the approach that is the main focus of this thesis. However, every approach is only worth as much as it can
offer. To determine this for the presented implementation -- \xmlmate, an empirical evaluation on several test
subjects has been carried out, and the results are documented in this section.
To state the research goals of the evaluation at hand more clearly, let me define them in terms of classic
research questions:
\begin{description}
  \item[RQ1] Is \xmlmate effective in finding defects?
  \item[RQ2] Is it efficient enough for practical reasons?
  \item[RQ3] What are the benefits of each fitness function?
  \item[RQ4] What is the impact of the schema violation mechanism?
\end{description}

At this point it is of particular importance to define what efficiency and
effectiveness mean in regards to this evaluation. 

Let \emph{effectiveness} be the measure of whether or not defects have been found in the time frame allocated
for an experiment run. Similarly, let \emph{efficiency} be the defect detection count for the same time frame.

\subsection{Evaluation Setup}
Due to the random nature of the genetic algorithm that is at the heart of \xmlmate, it is necessary to perform
multiple runs of each experiment in order to properly ascertain its effectiveness and efficiency statistically
by considering the average values.

One \emph{experiment} consists of running \xmlmate for one hour with a limit of 2200 elements per \xml instance
as well as a maximum recursion depth of 12 for optional elements, meaning that no optional elements are generated
for subtrees of depth 13 or more. Additionally, the maximum number of \xml files in the population being
evolved is limited to 500, which is kept consistent across the normal and the singleton population (see
\cref{sec:memcov}) modes as follows: in the singleton population usage scenario, where single files are the
main focus of the evolution process, the limit is expressed simply as a single suite with a maximum of 500
individual files in it, while in the other use case, where the result of an evolution is a suite of files, the
limit is enforced as a population of 25 suites with a maximum of 20 files in each.

These numbers were chosen empirically in a way that the overall performance on today's average developer
computer is perfectly acceptable, i.e.\ the execution of other programs at the same time remains unhampered.
The size of the population is appropriate because it is not too small to cause rapid deterioration of results
and not too large to become only laboriously usable.

To produce statistically significant average result values, for each fitness function and for each test
subject an experiment was run 10 times. This setup was replicated for the two modes of testing: with and
without the mechanism for producing schema-invalid values.

The experiments were carried out on a virtual machine equipped with 8 CPU cores running at 2.60GHz and 64 Gb
main memory, which, however, was far more than needed because the \java part of \xmlmate{} (the process taking
up the most memory) only needed 2Gb for in-memory \xml instance handling. The deployment configuration
of the \xmlmate system consisted of the following components:

\begin{itemize*}
  \item 1 instance of the \java \xmlmate core component
  \item 1 load balancer between the core component and converter instances
  \item 8 format converter instances
  \item 1 load balancer between the converters and the workers
  \item 8 worker instances (worker = test driver + test subject instance + pintool)
  \item 8 lifeguards for their respective workers
\end{itemize*}

The setup can be imagined as in \cref{fig:components} with $n = m = 8$.
It must be noted that no converters were used for \libxml, one of the test subjects, as it consumes
inputs as generated by the \xmlmate core component directly, therefore only one load balancer was needed between the generator
instance and the worker instances.

\subsection{Test Subjects}
While \cref{sec:formats} has introduced you to the file formats used in this document, the following sections
will give you a short description of programs that were used during the evaluation, which work with those
formats. Each test subject was chosen as a popular library for processing its corresponding file format.
\tocless\subsubsection{libxml2}
\libxml\footnote{\url{http://www.xmlsoft.org/}} is a library for processing generic \xml documents,
which is written in C. It is widely used and provides bindings to many programming languages
including \cpp, C\#, \python{}, Ruby, PHP5, and Perl. Furthermore, it was
designed for utmost portability, such that it works on a wide variety of operating systems such as
Linux, Windows, CygWin, MacOS, RISC Os, OS/2, and others. Notably, the Google Chrome
browser uses \libxml internally, which further shows the library's popularity.

The library is extremely well tested, and in its current version 2.9.2 it passes all tests from the very large
OASIS XML Test Suite\footnote{\url{https://www.oasis-open.org/committees/xml-conformance/xml-test-suite.shtml}}
consisting of more than 1800 individual tests. It is, therefore, very unlikely for \xmlmate to find any
vulnerabilities or even defects, especially because it specializes in generating \emph{valid} XML files, and
even more so in this case, where only \texttt{xhtml} files, which do not represent the entirety of the \xml
specification, were used for testing.

Since in its main functionality this library acts like a parser, the interface for performing testing with
\xmlmate is correspondingly simple: the test driver engages the library under test by passing it a file to be
parsed and loaded into memory, whereafter the file is unloaded. No additional walks are performed, which
sacrifices a lot in terms of achieved fitness scores, but wins out multiple times over in the
overall execution speed.

% download from https://git.gnome.org/browse/libxml2/refs/tags

\tocless\subsubsection{libpcap}
\libpcap\footnote{\url{http://www.tcpdump.org/}} is a library for working with the \pcap file format
maintained by the \emph{Tcpdump Group}. It is used in the popular tools tcpdump, ngrep, Wireshark, Snort and
nmap, among others. The main objective of \libpcap is to provide its users with a
platform-independent API for network packet capturing. The API is designed to work with the C and \cpp
programming languages, but there exists a number of bindings to other languages as well such as \python, \java,
C\#, or Ruby.

While it first and foremost provides a nice abstraction layer above the operating system-specific live packet
capturing mechanism (which every operating system vendor seems to have designed differently), \libpcap
also provides an interface for manipulating packets already captured and available in the \pcap file format.
This is the interface through which testing with \xmlmate is performed as it seems otherwise rather
infeasible to simulate a network card interface in order to engage \libpng on the live capturing
interface. One consequence of choosing the offline file reading interface is, however, that only a relatively
small portion of the program code of \libpcap can be possibly engaged. This limitation has to be kept
in mind when assessing the results of the empirical evaluation presented in this section. It is also noteworthy
to mention that to date there are no known vulnerabilities in \libpcap itself, while both tcpdump and
Wireshark seem to have corresponding entries in Internet vulnerability databases such as
\url{http://www.cvedetails.com}.

\tocless\subsubsection{libpng}
\libpng\footnote{\url{http://www.libpng.org/}} is a ubiquitous library for manipulating, reading,
writing and generally handling \png files. It is available freely under a permissive license, and thus very
widely used in a vast number of both free and proprietary software products. The \libpng library is
written in the C programming language and depends on the \texttt{zlib} library for data compression.
It is considered to be the reference implementation for all possible interactions with \png files.

In its 18 years of existence, the library was extensively tested as it evolved and matured. Ever since the very
early versions it provides \emph{pngtest} -- a utility that allows to test a \png file for conformance with the
\png file format. This process involves reading and parsing the file, storing it in memory, performing several
transformations on it, writing it out to disk again, and comparing the result with the original input file.
This seems like a good representation of the usual use case for this library, which is why it was chosen as
the interface at which testing with \xmlmate was performed. The test driver for \libpng basically
consists of pngtest itself slightly modified to enable communication with \xmlmate via \zmq. In order not
to waste computational resources, one limitation was imposed on the images generated by \xmlmate: their size
was limited to $2\times 2$ pixels because most defects found in \libpng originate from specific values
in the metadata rather than image data itself.

%\subsubsection{libflac}
\subsection{Results}
In the following sections the results of the conducted experiments are presented: first a general overview is
given of the fitness scores achieved by each fitness function alongside explanations and observations,
followed by examples of vulnerabilities found in the \libpng library, and finally, additional defects found in
related programs are discussed.

\subsubsection{Fitness Function Practicability}
The first experiment serves to investigate the practicability of each subject-oriented fitness function
presented in \cref{sec:fit} when applied to the proposed test subjects with and without the schema violation
mechanism in order to answer the research questions \textbf{RQ3} and \textbf{RQ4}. 
To accomplish this, a comparison
between the fitness scores achieved by each function for each subject is needed.
% One exception is the Schema Coverage fitness function, which is ignored here because using it only depends on
% the format specification and its quality and is thus independent from test subjects.
The subjects used for this comparison were taken from their respective official repositories, the versions
used were as follows: \libpng \texttt{1.5.4}, \libpcap \texttt{1.3.0}, and \libxml \texttt{2.8.0}. While the
\libpcap and \libxml versions were chosen as the most easily obtainable on the current stable branch of the
Debian operating system, the version of \libpng was chosen such that both fitness values for a general
comparison and defect search could be carried out at least in part simultaneously and with minimum effort.
(This particular version of \libpng has an unchecked division by zero defect.)

\Cref{tbl:fitness} gives an overview of
the fitness scores achieved by each fitness function. These scores are average values computed over the ten
experiment runs that were carried out for each fitness function. For each test subject the table has two rows
for both of the input generation modes: the one that strictly adheres to the format specification and thus
produces schema valid inputs, and the one that is able to ignore some specification rules. The former mode is
marked with a ``+'' sign in the \emph{Schema Valid} column, while the latter one is marked with a ``-'' sign.

\begin{table}[htb]
\small
\centering
\begin{tabular}{|r|c|r|r|r|r|r|r|}
\hline
\multicolumn{1}{|c|}{Subject}  & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Schema\\ Valid\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}BBL\\ Coverage\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}BBL\\ Succession\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Memory\\ Access\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}$\downarrow$ Division\\ by 0\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Integer\\ Overflow\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Buffer\\ Overflow\end{tabular}} \\ \hline \hline
                               & +                                                                           &              143.2                                                          &                          185.3                                                &                                470                                           &                          no divs                                           &                          7.0369E13                                             &                          2175400                                                               \\ \cline{2-8} 
\multirow{-2}{*}{libpcap}      & \cellcolor[HTML]{C0C0C0}-                                                   & \cellcolor[HTML]{C0C0C0} 152.8                                              & \cellcolor[HTML]{C0C0C0} 192                                                  & \cellcolor[HTML]{C0C0C0} 470                                                 & \cellcolor[HTML]{C0C0C0} no divs                                           & \cellcolor[HTML]{C0C0C0} 7.0369E13                                             & \cellcolor[HTML]{C0C0C0} 2175408                                                               \\ \hline \hline
                               & +                                                                           &                          14963                                              &                          11507                                                &                          4007                                                &                     1                                                      &                          4.6115E18                                             &                          2102329                                                               \\ \cline{2-8} 
\multirow{-2}{*}{libpng}       & \cellcolor[HTML]{C0C0C0}-                                                   & \cellcolor[HTML]{C0C0C0} 15330                                              & \cellcolor[HTML]{C0C0C0} 11657                                                & \cellcolor[HTML]{C0C0C0}  66493                                              & \cellcolor[HTML]{C0C0C0}      1                                            & \cellcolor[HTML]{C0C0C0}              4.6115E18                                & \cellcolor[HTML]{C0C0C0} 2102329                                                               \\ \hline \hline
                               & +                                                                           &       18650                                                                 &                          12576                                                &                            858058                                            &                                      128                                   &                          4.4175E18                                             &                          73728                                                                 \\ \cline{2-8} 
\multirow{-2}{*}{libxml2}      & \cellcolor[HTML]{C0C0C0}-                                                   & \cellcolor[HTML]{C0C0C0}    18987                                           & \cellcolor[HTML]{C0C0C0} 12791                                                & \cellcolor[HTML]{C0C0C0}   848560                                            & \cellcolor[HTML]{C0C0C0}    104.4                                          & \cellcolor[HTML]{C0C0C0} 4.6216E18                                             & \cellcolor[HTML]{C0C0C0} 73728                                                                 \\ \hline
\end{tabular}
\caption{Average Fitness Scores}
\label{tbl:fitness}
\end{table}

\paragraph{General Remarks} ~\\
The fitness scores differ significantly across the different fitness functions even for the same subject,
which is understandable because each of the functions has different metrics, which makes their scores
largely incomparable because the functions are designed to measure different characteristics of a
program's execution.

What might seem somewhat surprising however, is the great variance in scores for the same fitness function
across multiple subjects. For example take the difference for the Basic Block Coverage fitness function -- it
has a score of 15330 for \libpng and only 152.8 for \libpcap. 
A similar difference can also be seen in all fitness functions whose scores are directly related to the
complexity or richness of the inputs i.e.\ also the Basic Block Succession and the Memory Access fitness
functions. Two main reasons can be given to explain this difference:

The first is that even though both libraries provide extensive parsing and data manipulation capabilities,
the formats they are designed to process differ significantly in complexity themselves. This causes a
corresponding difference in parts of the code responsible for checking inputs for consistency and keeping
the data consistent during manipulation operations.

The second reason is in the nature of the test driver used with each subject: while the test drivers for
\libpcap and \libxml mostly exercise parsing capabilities, the test driver used for \libpng additionally
engages several data consistency checks and transformations as well as writing of output.

To provide further hints on possible idiosyncrasies found in \cref{tbl:fitness} please note that the four
rightmost fitness functions use the singleton population evolution model, which offers performance benefits,
which, in turn, might have an effect on the utilization of the time frame allotted for an experiment run and
thus the resulting fitness scores.

\paragraph{Basic Block Coverage Fitness Function} ~\\
The Basic Block Coverage fitness function provides a very basic and rather crude method to reach into a
program's logic. Possibly somewhat counterintuitively, it does not provide a way to estimate the complexity of
the application under test on its own. This is mainly because there is no guarantee that the entirety of
the program's functionality can be reached at all from the entry point chosen in the test driver. So this
fitness function rather provides a measure of the quality of the test harness itself, which can serve as a
tool for improving its quality, and also for interpreting results achieved by other fitness functions more
accurately by adjusting expectations accordingly.

This does not mean, however, that this fitness function does not provide any indication as to the complexity of
the program under test at all. Its scores are indeed proportionally indicative of the number of statements
present in the part of the code reachable from the test driver's entry point. Using this interpretation it can
be concluded that the extent of functionality engaged in \libpcap was an order of magnitude smaller than that
of \libpng and \libxml.

\begin{mdframed}
\centering
The Basic Block Coverage fitness can indicate the complexity of the test driver. 
\end{mdframed}

\paragraph{Basic Block Succession Fitness Function} ~\\
As a more involved fitness function also concerning itself with basic blocks, the Basic Block Succession
fitness function provides a different view on the complexity of the program behavior engaged by the test
driver.
While the previous fitness function merely indicates the extent of a subject's engaged functionality, this
fitness function illuminates its degree of coupling or interconnectedness. It shows not only how much
functionality has been reached, but also how it was reached i.e.\ which paths were taken during execution.

The findings of this fitness function seem to suggest that while the complexity gap between \libpcap and the
two other subjects found by the previous fitness function is legitimate, the gap of approx.\ 3500 basic blocks
between \libpng and \libxml is an overestimation as the difference in interconnectedness is not appropriately
large. Because the test drivers are not equivalent and the \libpng driver involves more complex
behavior, the findings of this fitness function lead to the conclusion that the large number of execution
subpaths taken by \libxml must result from the increased expense of parsing its text based input format, which
\libpng is lacking due to its inputs being in binary format already. This possibly also explains the larger
number of basic blocks an input has to pass through in \libxml.

\begin{mdframed}
\centering
The Basic Block Succession fitness indicates the degree of coupling in reachable code.
\end{mdframed}

\paragraph{Memory Access Fitness Function} ~\\
The scores achieved by the Memory Access fitness function indicate how much memory is accessed by the
application under test when processing an input file. Please note that this function is somewhat simplistic.
Its values are not always proportional to the size of the inputs as there is no guarantee that the program
under test will load all data into its memory at once -- it could just as easily process the input using a
buffer or a sliding window technique only ever reusing the same constant memory space.
Additionally, the scores of this fitness function are heavily influenced by how many operations on the input
data are performed by the tested application -- e.g.\ the \libpng driver first reads the data, manipulates
it, and finally writes it out again, performing at least three passes over not necessarily the same regions of
memory. Nevertheless, the Memory Access fitness function is a very helpful tool in detecting program defects
related to memory operations, as you will see in the next section. 

Taking a closer look at the outcome of the experiments, the result for \libpng is in need of special
attention because of the very large difference between scores for schema-valid and invalid inputs of 4007 and
66493, respectively. To explain this, please note that \libpng loads its input entirely into memory, which
makes the values for the Memory Access fitness function proportional to the input size in this case. Now, with
the generator occasionally violating schema restrictions based on numbers, the $2\times 2$ pixel limitation is
happily ignored and images with very large dimensions are produced, which easily consume significantly more
memory. E.g.\ if the generator produces image data of size $12 \times 10$, the memory consumption is increased
30-fold. This increase leads to a corresponding increase in the fitness score, which favors the production
of even larger images generation after generation.

\begin{mdframed}
\centering
The Memory Access fitness gives an estimation of the spread of memory interactions.
\end{mdframed}

\paragraph{Division by Zero Fitness Function} ~\\
In accordance with their respective descriptions (listed in \cref{sec:fit}), all fitness functions
presented in \cref{tbl:fitness} are maximization functions with the exception of the Division by Zero fitness
function, which is a minimization function -- it is therefore marked with a downward arrow ($\downarrow$) in the
table to signify that smaller values are considered better.

This particular fitness function was unfortunately useless in the case of \libpcap because no division
instructions could be detected. There might still be division instructions present in the code, which were
simply undiscovered due to the limited reach of the test driver, or the division instructions used were of a
kind that is unsupported in the current version of the fitness function such as SIMD instructions that deal
with entire arrays of data simultaneously.

The lowest average divisor value reached for \libxml was 104.4, which is already better, but still nowhere near
a desired division by zero. The minimal observed divisor value was 10, but it only appeared twice over the
course of the ten experiments. It seems that this library does not have a distinctive correlation between user
data and the divisions performed.

It might seem strange that the best score for the Division by Zero fitness function for \libpng is 1 even
though the version of \libpng used for this particular experiment has an unchecked arithmetic exception
defect. Clearly a value of 0 would be expected, especially considering that this defect is, in
fact, found by \xmlmate rather easily. The explanation for this score is actually quite simple: the inputs
that would have a perfect score of 0 are actually crashing the tested program, which means that their
fitness is only reported as ``crashed'' to the genetic algorithm. It is, of course, possible to assign
the best fitness score to such inputs, however this would only lead to more crashes due to the same
defect, and also severely hinder the diversity of the gene pool as more and more inputs would simply become
very similar because of the perfect fitness score. Therefore such inputs are instead given the worst possible
fitness score in order to be phased out of the population to make room for new mutations. This way, at the end
of the evolution only individuals that are as close as possible to having a perfect score without actually
reaching it are reported as the best individuals produced during the process. This, of course, is only an
implementation detail, and a value of zero could be justifiably put in \cref{tbl:fitness}.

\begin{mdframed}
\centering
The Division by Zero fitness is a powerful tool for detecting arithmetic exceptions.
\end{mdframed}

\paragraph{Integer Overflow Fitness Function} ~\\
As another arithmetic-based fitness function, the Integer Overflow fitness function tries to steer the
evolution of inputs towards inducing computations of great magnitude. According to the scores achieved during
the experiments, the computations were indeed large, and once again, there is a gap several orders of
magnitude in size between the values for \libpcap and the two other test subjects. Combined with the
results provided by the Memory Access fitness function, it appears as though this library does sliding window
processing of its file inputs, and therefore no very large computations related directly to the values in
the inputs themselves are performed. When examining the fitness values over the course of evolution, it can
be seen that the value that will ultimately become the result is reached in the early generations already.
This fitness function might be worth improving in the future, yet even in its current simple
implementation it is able to detect some vulnerabilities, as will be shown later.

\begin{mdframed}
\centering
The Integer Overflow fitness is a simplistic guidance criterion towards overflows.
\end{mdframed}

\paragraph{Buffer Overflow Fitness Function} ~\\
The Buffer Overflow fitness function, whose aim it is to favor memory accesses at the edges of allocated
buffers, produced results which seem surprising as they do not adhere to the trend established by the other
fitness functions -- for this fitness function, it is \libpcap which has the largest score. One explanation
that can be given is that, as discussed in the previous section, \libpcap processes its inputs with a sliding
window, which occupies approximately 4mb (estimated as roughly twice the buffer access distance). 
According to the results found by the Memory Access fitness function, this reserved buffer is most likely not
relocated during the program's lifetime, thus occupying the same memory addresses, such that accesses to
different data within the same buffer do not count as unique accesses according to the definition of that
fitness function. Further, this means that this buffer is likely to be probed at some points instead of being
accessed linearly in the case of the test driver used in this experiment. 

The similar Buffer Overflow fitness value for \libpng, especially when regarded together with its results for
the Memory Access fitness function, suggests that while \libpng loads its entire input into memory and
accesses it at a lot of unique addresses, it stores them in chunks, for which it reserves different buffers.

On the other hand, \libxml does not seem to reserve particularly large buffers at all, mostly because the data
it manages is tree structured, which imposes no need for large contiguous allocations, as it is sufficient to
store each tree node in its own small buffer.

\begin{mdframed}
\centering
The Buffer Overflow fitness is indicative of internal memory management strategies.
\end{mdframed}

\paragraph{Impact of Schema Violation} ~\\
At this point, it is worth remembering that running the experiments in schema violation mode causes a
significant strain on the utilization of the time allotted for each experiment run. Because schema violation
is implemented by means of the local search mechanism, setting the corresponding frequency parameter to
$n$ causes the genetic algorithm to lose every $n_{th}$ generation in the worst case. For a
reasonable trade-off between benefiting from schema violation and forgoing some generations an empirically
established value of $n=3$ was chosen.

According to the experimental results listed in \cref{tbl:fitness}, schema violation has a noticeable impact in
most cases; especially so for fitness functions, whose value is directly dependent on the complexity of the
engaged program behavior (i.e.\ the four leftmost fitness functions). Most likely the reason for this are the
very input validation mechanisms mentioned at the beginning of this document, which motivated this work in the
first place: when confronted with inputs malformed in a nonrecoverable manner, the validation mechanisms of the
program under test engage different behavior mostly associated with producing appropriate error messages,
which leads to more code being executed and different memory regions being accessed.

In cases where the fitness score is not necessarily dependent on the values of the inputs themselves, but
rather their characteristics (e.g.\ their size, or presence/absence of particular structures), the schema
violation mechanism does seem to have any noticeable effect, as seen in the cases of Integer and Buffer
Overflow fitness functions.

Returning to the previously mentioned performance vs.\ usefulness trade-off of using the schema violation
mechanism, it must be noted that for the Memory Access fitness function applied to \libxml, schema
violation only reduced the fitness score. This is the case because the format used is \texttt{xhtml}, which
means that no structurally invalid instances are ever generated even with violation active, only the
particular numbers inside \xml elements and attributes can be outside their specification range, which is, of
course, of no consequence to a generic \xml parser such as \libxml. In this particular case the only
noticeable effect of using the schema violation mechanism is that is wastes every third generation as it is
unable to improve the fitness score by reaching previously inaccessible memory regions.

\begin{mdframed}
The schema violation mechanism provides a worthwhile enhancements in many cases.
\end{mdframed}

% \begin{table}[H]
% \small
% \centering
% \begin{tabular}{|c||r|r|r|r|r|r|}
% \hline
% \begin{tabular}[c]{@{}c@{}}Schema\\ Valid\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}BBL\\ Coverage\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}BBL\\ Succession\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Memory\\ Access\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Division\\ by 0\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Integer\\ Overflow\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Buffer\\ Overflow\end{tabular}} \\ \hline
% + & ? & ? & ? & 13.2 & 9.2 & 12.9 \\ \hline
% - & 1.8 & 1.6 & 1.2 & 12.0 & ? & 16.1 \\ \hline
% \end{tabular}
% \caption{Average Division by Zero Defect Count for \texttt{libpng 1.5.4}}
% \label{tbl:png:crashes:avg}
% \end{table}
% Explanation for div0^{ls} < div0: ls uses the time resource, but doesn't provide a benefit because the zero is already legal


\subsubsection{Effectiveness and Efficiency}
In this second experiment the goal is to ascertain the effectiveness and efficiency (as defined at the
beginning of this section) of \xmlmate as a search-based tool for defect detection in order to answer the
research questions \textbf{RQ1} and \textbf{RQ2}. This experiment consists of
an empirical study concerning itself solely with the \libpng library. \Cref{tbl:png:vulns} shows a selection of known vulnerabilities in \libpng
chosen as indicators for determining the effectiveness and efficiency of \xmlmate. The vulnerabilities are
listed alongside the corresponding vulnerable program version and their CVSS -- a score on a scale from 0 to 10
that indicates the severity of a vulnerability.
The vulnerabilities were selected in a way that both low and high CVSS scores were represented, as well as
different library releases, but most importantly they were selected such that they make the test driver crash,
which is an effect definitely detectable in the use case of input fuzzing. It is incomparably much harder
to detect subtle vulnerabilities that do not lead to an application crash, which is why they are out of scope of
this work.

The experiment itself consisted of running \xmlmate against each version of \libpng ten times for an hour,
whereby each vulnerability was targeted with a limited selection of fitness functions most appropriate for
its respective nature.

% as listed in https://wiki.mmci.uni-saarland.de/syssec/Vulnerabilities/libpng
\begin{table}[H]
\centering
\begin{tabular}{|r|c|r@{}l|l|}
\hline
Vulnerability & CVSS  & \multicolumn{2}{c|}{Version} & Short Description \\ \hline \hline 
CVE-2011-3328 & 2.6   & 1&.5.4 	& Arithmetic exception: division by zero   \\ \hline  % div0(10/132)
CVE-2011-2691 & 5.0   & 1&.5.2	& Null pointer dereference in error message \\ \hline % buf(36/5k), mem(10/430)
CVE-2013-6954 & 5.0   & 1&.6.6  & Null pointer dereference on empty palette \\ \hline % buf(10/157), bbl2, mem
CVE-2011-3048 & 6.8   & 1&.5.9  & Unchecked failing malloc in constrained memory \\ \hline % mem(127/3449), buf 
CVE-2008-1382 & 7.5   & 1&.2.25 & Segmentation fault on unknown chunks of size 0\\ \hline % bbl2(20/0), schemaCov
\end{tabular}
\caption{Vulnerabilities in \libpng Versions}
\label{tbl:png:vulns}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|r|}
\hline
Vulnerability                  & Fitness Function & \texttt\#found \texttt{/} hour \\ \hline \hline
CVE-2011-3328                  & Division by Zero & 13.2           \\ \hline \hline
\multirow{2}{*}{CVE-2011-2691} & Buffer Overflow  & 138.8          \\ \cline{2-3} 
                               & Memory Access    & 43             \\ \hline \hline
CVE-2013-6954                  & Buffer Overflow  & 15.7           \\ \hline \hline
\multirow{2}{*}{CVE-2011-3048} & Memory Access    & 27.2           \\ \cline{2-3}
							   & Integer Overflow & 6.3			   \\ \hline \hline
\multirow{2}{*}{CVE-2008-1382} & BBL Succession   & 623            \\ \cline{2-3}
                               & Schema Coverage  & 1              \\ \hline
\end{tabular}
\caption{\textsc{XMLMate's} Vulnerability Detection Rates}
\label{tbl:png:rates}
\end{table}
% ??? update for more FFs

\Cref{tbl:png:rates} shows the average detection rate for each of the vulnerabilities listed in
\cref{tbl:png:vulns} as well as the fitness function used in each experiment run. It must be noted that when
testing for {\small CVE-2011-3048}, the amount of main memory available to the test driver was artificially
limited to 450mb because this particular vulnerability only manifests itself in case \texttt{malloc} is unable
to reserve sufficient memory. It must further be remarked that the \pin instrumentation framework and the
pintool implementing a fitness function share their memory with the program under test, which effectively
reduces the amount of memory available to the the program's allocator.
 
The experimental results suggest that \xmlmate is indeed both effective and efficient as a defect detection
tool, finding every targeted vulnerability multiple times over in the span of one hour. Additionally, by
testing the targeted applications on the system level, \xmlmate avoids false positives, which makes the
reported findings even more valuable.

% bblcov2 12142 after 23h
% ??? mention problem of failure masking -> one crash makes another undetectable

\subsubsection{Serendipitous Findings}
In the process of running the experiments needed for this evaluation several defects were found in programs
related to the used file formats, which were not specifically targeted. Here are the most interesting of them.
\paragraph{Gimp} ~\\
The GNU Image Manipulation Program\footnote{\url{http://www.gimp.org/}} (\texttt{gimp}) is an open source
application, which is capable of opening and editing \png files. The latest available version of \texttt{gimp}
is \texttt{2.8.2} on the current stable branch of the Debian operating system, which, at the time of writing,
is ``Wheezy''. In this version \texttt{gimp} has a defect that results in immediate program termination upon
opening a specially crafted \png file due to a segmentation fault. To cause this, the \png file must
simply contain a \texttt{PLTE} chunk with an empty data region. This defect is no longer present in later
versions of \texttt{gimp}, although it is not listed at \url{http://www.cvedetails.com}.
\paragraph{Wireshark} ~\\
Wireshark\footnote{\url{https://www.wireshark.org/}} is a cross-platform open source program for network packet
inspection and analysis. Its latest version available on the aforementioned Debian configuration is
\texttt{1.8.2} and this version has the following defect, which is also present in the same version on the
Windows 7 x64 operating system: when opening a specially formed \pcap file the application terminates and
prints the following error message on the console:

{\small ("Null pointer passed to bytes\_to\_hexstr\_punct()", group=1, code=4) in file to\_str-unt.h}

This defect is not present in the newest version of Wireshark, but it is also not listed among the known
vulnerabilities at \url{http://www.cvedetails.com}. This particular defect was found when \xmlmate reported to
have crashed a \libpcap worker instance. Unfortunately, the crash in \libpcap itself could not be reproduced,
but while trying to inspect the generated \pcap file, Wireshark crashed instead. It is still possible that
this file actually crashed \libpcap, but some other conditions were involved not directly controlled by the
experiment; this investigation could present a topic for a future work item.
\paragraph{Firefox} ~\\
Input files for testing \libxml are generated in the \texttt{xhtml} format, which is primarily a web page
description format, so several of them were opened in different web browsers for manual inspection. As a side
effect several files exhibiting interesting behavior in modern browsers were found. The most notable is a 161KB
sized file that causes the latest Firefox web browser (version \texttt{37.0.2} at the time of writing) to
consume several gigabytes of memory and promptly crash. The size of the input file can most certainly be
reduced even further by using a variation on the delta debugging technique\cite{zeller2002simplifying}. 

The latest nightly build of Firefox does not exhibit this behavior as it behaves very similarly to the 
latest Google Chrome web browser (version \texttt{42.0.2311.90}) in that it freezes up for a
considerable amount of time and then displays a notification informing the user that the page could not be
loaded.

\begin{mdframed}
Inputs generated by \xmlmate are so elaborate, that they have revealed previously unknown defects in several
applications which were not even specifically targeted.
\end{mdframed}

\subsection{Threats to Validity}
As any empirical study, this evaluation is subject to several threats to validity.
First, as regards \emph{external validity}, the subjects used in this study may be far from representative of
the entirety of all applications now compatible with \xmlmate, and may even be uncharacteristic among their
respective application class.

Concerning \emph{internal validity}, it must be kept in mind that search-based testing is random in nature, and
thus the results may vary greatly over multiple experiments. Some effort was made to mitigate this problem by
performing multiple runs and taking the average results. However, it is unclear if a much larger sample size
would alter the results in any significant way.

Furthermore, the choice of many of the parameters for the genetic algorithm such as population size,
genetic operation probabilities, or chromosome limitations might not have been optimal for the chosen test
subjects. Additionally, the results are dependent on the quality of the corresponding \xsd, format converter,
and test driver.

Regarding \emph{construct validity}, it cannot be stated with absolute certainty that the metrics used in the
evaluation are well suited to adequately measure the efficiency and effectiveness of the presented approach.
In particular the defects targeted as indicators were chosen such that they crash the program under
test, which may not be representative of software defects in general. 
